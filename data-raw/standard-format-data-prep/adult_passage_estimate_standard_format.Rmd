---
title: "adult_upstream_passage_estimates_standard_format"
output: html_document
date: "2023-02-10"
---

```{r, include = F}
library(dtplyr)
library(data.table)
library(tidyverse)
library(lubridate)
library(googleCloudStorageR)
library(knitr)
library(hms)
library(here)

root.dir <- rprojroot::find_rstudio_root_file()
knitr::opts_knit$set(root.dir)
knitr::opts_chunk$set(echo = TRUE)
```

```{r, data_pull, include = F, echo = F, eval = F}
# Data pull ---------------------------------------------------------------
gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))

# pull in grandtab data. this data was extracted from https://nrm.dfg.ca.gov/FileHandler.ashx?DocumentID=84381 for spring run only
# using tabula and then cleaned up. sacramento river was not included because it is unknown where that data is coming from.
gcs_get_object(object_name = "adult-upstream-passage-monitoring/grandtab_spring.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "grandtab_spring.csv"),
               overwrite = TRUE)

# pull in standard format data to compare estimates
gcs_get_object(object_name = "standard-format-data/standard_adult_upstream_passage.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "standard_adult_upstream_passage.csv"),
               overwrite = TRUE)

# pull in battle passages estimates that were scraped from 2020 report: https://storage.cloud.google.com/jpe-dev-bucket/adult-upstream-passage-monitoring/battle-creek/data-raw/2020%20Battle%20Creek%20Adult%20Monitoring%20Report.pdf
gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/battle-creek/data-raw/battle_spring_passage_estimates.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "battle_spring_passage_estimates.csv"),
               overwrite = TRUE)

# pull in yuba passage estimates that were pulled from https://storage.cloud.google.com/jpe-dev-bucket/adult-upstream-passage-monitoring/yuba-river/data-raw/2020%20Update%20LYR%20Chinook%20Salmon%20Run%20Differentiation_December%202020.pdf
gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/yuba-river/data-raw/yuba_escapement_values.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "yuba_spring_passage_estimates.csv"),
               overwrite = TRUE)

# pull in butte creek vaki estimates
# https://www.calfish.org/ProgramsData/ConservationandManagement/CentralValleyMonitoring/SacramentoValleyTributaryMonitoring/ButteCreek.aspx
gcs_get_object(object_name = 
                 "adult-holding-redd-and-carcass-surveys/butte-creek/Butte_Creek_Historic_Escapement.csv",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "butte_escapement.csv"),
               overwrite = TRUE)
```

```{r, data_pull, include = F, echo = F, eval = F}
# pull deer and mill creek estimates
# raw data files are in the google bucket sent from Doug Killam
# estimates were extracted manually and that file is in the google bucket
gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/mill-creek/data-raw/mill_estimates_manual_extract.xlsx",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "mill_escapement_estimates.csv"),
               overwrite = TRUE)

gcs_get_object(object_name = 
                 "adult-upstream-passage-monitoring/deer-creek/data-raw/deer_estimates_manual_extract.xlsx",
               bucket = gcs_get_global_bucket(),
               saveToDisk = here::here("data", "deer_escapement_estimates.csv"),
               overwrite = TRUE)
```

# Deer Creek Passage Estimates

- Deer Creek has passage estimates from 2013-2023. Doug Killam (Doug.Killam@wildlife.ca.gov) is the contact and provided individual data sheets with the raw and interpolated counts for each year. They are in slightly different formats based on the year.
- They were manually extracted and entered into an excel for speed, but raw files are in the bucket.

```{r}
deer_raw <- readxl::read_excel(here::here("data", "deer_escapement_estimates.csv"))


# deer creek 2014 collects north and south ladders separately; for 
# all other years, take the "both" estimate to avoid double counting
deer <- deer_raw |> 
  mutate(keep_ladder = ifelse(year == 2014 & ladder %in% c("north", "south") | year != 2014 & ladder == "both", TRUE, FALSE)) |> 
  filter(species == "chinook", keep_ladder) |> 
  select(-c(is_count, percent_grilse, percent_hatchery, file_source, keep_ladder)) |> 
  glimpse()
```

# Mill Creek Passage Estimates

- Mill Creek has passage estimates from 2007-2023. Doug Killam (Doug.Killam@wildlife.ca.gov) is the contact and provided individual data sheets with the raw and interpolated counts for each year. They are in slightly different formats based on the year.
- They were manually extracted and entered into an excel for speed, but raw files are in the bucket.

```{r}
mill_raw <- readxl::read_excel(here::here("data", "mill_escapement_estimates.csv"))

mill <- mill_raw |> 
  filter(species == "chinook") |> 
  mutate(run = ifelse(run == "NA", "not recorded", run)) |> 
  select(-c(species, file_source, note)) |> 
  glimpse()
```

```{r}
spring_grandtab <- read_csv(here::here("data", "grandtab_spring.csv"))
adult_passage_standard <- read_csv(here::here("data", "standard_adult_upstream_passage.csv"))
battle_spring <- read_csv(here::here("data", "battle_spring_passage_estimates.csv")) |> 
  rename(year = `...1`)
yuba <- read_csv(here::here("data", "yuba_spring_passage_estimates.csv"))
# need to pull vaki numbers
butte <- read_csv(here::here("data", "butte_escapement.csv")) |> 
  select(Year, Vaki) |> 
  filter(!is.na(Vaki))
```

```{r, include = F}
# what is in grandtab is exactly the same as what is in the report for battle creek
compare_battle <- left_join(spring_grandtab, battle_spring) |> 
  select(year, battle, passage_estimate)
# for the years where does has passage estimates, passage estimate data is very similar

# looks like yuba doesn't really report to grandtab
compare_yuba <- left_join(spring_grandtab, yuba) |> 
  select(year, yuba, spring_run_escapement)
```

Conclusions based on comparisons:
- use grandtab for battle, clear
- use cleaned raw files for deer, mill
- yuba we will pull from report

# Create table of annual passage estimates by stream

```{r}
# decided to remove years prior to 1994 because all NA

# pull data from grandtab because it matches the data in the battle report
# and is easier to process from grandtab
clear_battle <- select(spring_grandtab, year, battle, clear) |> 
  rename(`battle creek` = battle,
         `clear creek` = clear) |> 
  pivot_longer(cols = c("battle creek","clear creek"), names_to = "stream", values_to = "passage_estimate") |> 
  filter(year >= 1995) |> 
  mutate(run = "spring",
         adipose_clipped = F)

# data are provided by Doug Killam
# run is recorded for mill creek
# all raw data files for deer creek are titled "spring"
deer_mill <- bind_rows(deer |> 
                         mutate(run = "spring"), mill) |> 
  group_by(stream, year) |> 
  rename(passage_estimate = estimate) |> 
  mutate(run = "spring",
         adipose_clipped = NA) |> # TODO incorporate percent hatchery?
  select(-species)

# from report provided by yuba
yuba <- select(yuba, year, spring_run_escapement) |> 
  rename(passage_estimate = spring_run_escapement) |> 
  mutate(stream = "yuba river") |> 
  mutate(run = "spring",
         adipose_clipped = F)

# no interpolation for butte creek - raw data counts, so no uncertainty
butte <- butte |> 
  rename(year = Year,
         passage_estimate = Vaki) |> 
  mutate(stream = "butte creek") |> 
  mutate(run = "spring",
         adipose_clipped = F)

passage_estimate <- bind_rows(clear_battle,
                              deer_mill,
                              yuba,
                              butte) |> 
  mutate(passage_estimate = round(passage_estimate, 2))

write_csv(passage_estimate, here::here("data","adult_passage_estimate.csv"))
```


```{r, save_data}
f <- function(input, output) write_csv(input, file = output)

gcs_upload(passage_estimate,
           object_function = f,
           type = "csv",
           name = "standard-format-data/standard_adult_passage_estimate.csv",
           predefinedAcl = "bucketLevel")
```